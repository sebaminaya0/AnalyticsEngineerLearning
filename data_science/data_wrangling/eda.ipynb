{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA (Exploratory Data Analysis)\n",
    "\n",
    "> We will work our own EDA on the following [Deepnote notebok](https://deepnote.com/workspace/sebastian-minaya-a67e42f1-471f-4ef3-b708-827621c005a4/project/Curso-EDA-Communication-Duplicate-829d77b8-46d3-4ab9-bd18-e867a252bb80/notebook/1.0-jvelezmagic-conociendo-nuestros-datos-2a5ad82e8af540619589fae1d201dec4)\n",
    "\n",
    "## What is EDA?\n",
    "\n",
    "EDA is a process of analyzing data to summarize their main characteristics, often with visual methods. It is a very important step in data analysis and data science. It is also the first step in data analysis, after data collection and before data modeling.\n",
    "\n",
    "## Why EDA?\n",
    "\n",
    "EDA is important because it helps us to understand the data and make conclusions about the data. It also helps us to find patterns in data and to determine relationships between variables. It is also used to confirm assumptions and to check the quality of the data.\n",
    "\n",
    "## What are the steps in EDA?\n",
    "\n",
    "1. Formulate a question\n",
    "\n",
    "    * What do you want to know?\n",
    "    * What do you want to prove?\n",
    "    * What is the reason for the analysis? <br><br>\n",
    "\n",
    "2. Determine the size of the data\n",
    "\n",
    "    - How many observations are there?\n",
    "    - How many variables are there?\n",
    "    - Do I need all observations and variables? <br><br>\n",
    "\n",
    "3. Determine the type of data\n",
    "\n",
    "    - How many categorical variables are there?\n",
    "    - How many numerical variables are there?\n",
    "    - How can I explore each variable? <br><br>\n",
    "\n",
    "4. Clean and validate the data\n",
    "\n",
    "    - Remove duplicates\n",
    "    - Remove missing values\n",
    "    - Remove outliers\n",
    "    - Correct data types\n",
    "    - Correct spelling errors\n",
    "    - Correct inconsistent data\n",
    "    - Correct inaccurate data\n",
    "    - Correct incomplete data\n",
    "    - Correct invalid data\n",
    "    - Correct irrelevant data\n",
    "    - Correct improperly formatted data\n",
    "    - Check for missing values\n",
    "    - Check for outliers\n",
    "    - Check for data types\n",
    "    - Check for spelling errors\n",
    "    - Check for inconsistent data\n",
    "    - Check for inaccurate data\n",
    "    - Check for incomplete data\n",
    "    - Check for invalid data\n",
    "    - Check for irrelevant data\n",
    "    - Check for improperly formatted data\n",
    "    - What is the proportion of missing values?\n",
    "    - How can I handle missing values?\n",
    "    - What is the data distribution?\n",
    "    - Are there any outliers? <br><br>\n",
    "\n",
    "5. Stablish the relationship between variables\n",
    "\n",
    "    - What is the relationship between variable X and variable Y?\n",
    "    - What happens if I consider Z instead of Y?\n",
    "    - What does it mean for observations to be similar?\n",
    "    - What does this trend mean? <br><br>\n",
    "\n",
    "6. Make conclusions \n",
    "    - What can I conclude from the analysis?\n",
    "    - What are the limitations of the analysis?\n",
    "    - What are the next steps?\n",
    "\n",
    "## What are the types of data analysis?\n",
    "\n",
    "Some of the types of data analysis are:\n",
    "\n",
    "1. Descriptive analysis: It is used to describe, summarize and find patterns in data.\n",
    "\n",
    "2. Diagnostic analysis: It is used to find the cause of an event.\n",
    "\n",
    "3. Predictive analysis: It is used to make predictions about future events based on past data.\n",
    "\n",
    "4. Prescriptive analysis: It is used to find the best solution to a problem.\n",
    "\n",
    "## What are the types of EDA?\n",
    "\n",
    "Some of the types of EDA are:\n",
    "\n",
    "1. Univariate analysis: It is used to describe, summarize and find patterns in a single variable.\n",
    "\n",
    "2. Bivariate analysis: It is used to find the relationship between two variables.\n",
    "\n",
    "3. Multivariate analysis: It is used to find the relationship between more than two variables.\n",
    "\n",
    "## What are the tools for EDA?\n",
    "\n",
    "Some of the tools for EDA are:\n",
    "\n",
    "1. Cloud based\n",
    "\n",
    "    - Google Colab\n",
    "    - Kaggle\n",
    "    - Databricks\n",
    "    - IBM Watson Studio\n",
    "    - Amazon SageMaker <br><br>\n",
    "\n",
    "2. Desktop based\n",
    "\n",
    "    - Jupyter Notebook\n",
    "    - RStudio\n",
    "    - PyCharm\n",
    "    - Spyder\n",
    "    - Visual Studio Code <br><br>\n",
    "\n",
    "## Steps to perform EDA\n",
    "\n",
    "1. Data collection\n",
    "\n",
    "    - Data can be collected from different sources such as:\n",
    "        - Web scraping\n",
    "        - APIs\n",
    "        - Databases\n",
    "        - CSV files\n",
    "        - Excel files\n",
    "        - JSON files\n",
    "        - XML files\n",
    "        - Text files\n",
    "        - PDF files\n",
    "        - Images\n",
    "        - Videos\n",
    "        - Audio files\n",
    "        - Social media\n",
    "        - Sensors\n",
    "        - IoT devices\n",
    "        - etc. <br><br>\n",
    "    - There are types of data collection:\n",
    "        - Primary data collection: It is the process of collecting data directly from the source.\n",
    "        - Secondary data collection: It is the process of collecting data from a third party source.\n",
    "        - Tertiary data collection: It is the process of collecting data from a third party source that has already collected data from another source. <br><br>\n",
    "\n",
    "2. Data cleaning and validation\n",
    "\n",
    "    - Data cleaning is the process of removing or correcting inaccurate, incomplete, irrelevant, duplicated or improperly formatted data.\n",
    "    - Data validation is the process of checking the accuracy, completeness, consistency, relevancy and validity of data.\n",
    "    - For data cleaning and validation looking at these is important:\n",
    "        - Data Model: If a third party collected the data, verify what questions they wanted to answer with the data. If you are the one collecting the data, ask yourself many questions and consider if that data is sufficient to answer them.\n",
    "        - Standard File Format Tracking: Verify that the file extensions you are handling correspond to the internal format they have. Make sure that numbers are expressed in the format you are working with.\n",
    "        - Data Types: Verify that the data is of the type indicated in the dataset.\n",
    "        - Variable Range: Verify that the variables are within the range established in the data collection. In case of finding variables outside the range, ask yourself: how did that data get here? Do they have any alternate meaning? Should I preserve or eliminate them?\n",
    "        - Uniqueness: Verify how unique the data is. Detect if there is duplication in the data and correct it.\n",
    "        - Consistency of Expressions: Refers to how the person collecting the data defines their variables. Date format, time format, variables written in the same way throughout the table. They are not erroneous data, it is just a matter of giving them the appropriate format.\n",
    "        - Null Values: They can be explicit or implicit in the dataset. They are missing data. Why is it empty? Can I fill it with another data? Is it empty due to a random process or does it have a meaning? <br><br>\n",
    "\n",
    "3. Data exploration\n",
    "\n",
    "    1. Univariate Data Exploration\n",
    "\n",
    "        - Univariate data exploration is the process of exploring a single variable.\n",
    "        - Some of the techniques used in univariate data exploration are:\n",
    "            - Histograms\n",
    "            - Box plots\n",
    "            - Bar plots\n",
    "            - Pie charts\n",
    "            - Frequency tables\n",
    "            - Descriptive statistics\n",
    "            - etc. <br><br>\n",
    "\n",
    "    2. Bivariate Data Exploration\n",
    "\n",
    "        - Bivariate data exploration is the process of exploring two variables.\n",
    "        - Some of the techniques used in bivariate data exploration are:\n",
    "            - Scatter plots\n",
    "            - Line plots\n",
    "            - Bar plots\n",
    "            - Box plots\n",
    "            - Correlation\n",
    "            - etc. <br><br>\n",
    "\n",
    "    3. Multivariate Data Exploration\n",
    "\n",
    "        - Multivariate data exploration is the process of exploring more than two variables.\n",
    "        - Some of the techniques used in multivariate data exploration are:\n",
    "            - Scatter plots\n",
    "            - Line plots\n",
    "            - Bar plots\n",
    "            - Box plots\n",
    "            - Correlation\n",
    "            - etc. <br><br>\n",
    "\n",
    "## PMF, PDF and CDF\n",
    "\n",
    "1. PMF (Probability Mass Function)\n",
    "\n",
    "    - The probability mass function (PMF) is a function that gives the probability that a discrete random variable is exactly equal to some value.\n",
    "    - The probability mass function (PMF) is important because it allows us to make predictions about the future based on past data. <br><br>\n",
    "\n",
    "2. PDF (Probability Density Function)\n",
    "    \n",
    "    - The probability density function (PDF) is a function that gives the probability that a continuous random variable is exactly equal to some value.\n",
    "    - The probability density function (PDF) is important because it allows us to make predictions about the future based on past data. <br><br>\n",
    "\n",
    "3. CDF (Cumulative Distribution Function)\n",
    "\n",
    "    - The cumulative distribution function (CDF) is a function that gives the probability that a random variable is less than or equal to some value.\n",
    "    - The cumulative distribution function (CDF) is important because it allows us to make predictions about the future based on past data. <br><br>\n",
    "\n",
    "## Law of Large Numbers and Central Limit Theorem\n",
    "\n",
    "1. Law of Large Numbers\n",
    "\n",
    "    - The law of large numbers states that as the number of trials increases, the average of the results approaches the expected value.\n",
    "    - The law of large numbers is important because it allows us to make predictions about the future based on past data. <br><br>\n",
    "\n",
    "\n",
    "2. Central Limit Theorem\n",
    "\n",
    "    - The central limit theorem states that as the number of trials increases, the distribution of the results approaches a normal distribution.\n",
    "    - The central limit theorem is important because it allows us to make predictions about the future based on past data. <br><br>\n",
    "\n",
    "## Choosing the right correlation coefficient\n",
    "\n",
    "1. Pearson Correlation Coefficient\n",
    "\n",
    "    - The Pearson correlation coefficient is a measure of the linear correlation between two variables.\n",
    "    - The Pearson correlation coefficient is important because it allows us to make predictions about the future based on past data. <br><br>\n",
    "\n",
    "2. Spearman Correlation Coefficient\n",
    "\n",
    "    - The Spearman correlation coefficient is a measure of the monotonic correlation between two variables.\n",
    "    - The Spearman correlation coefficient is important because it allows us to make predictions about the future based on past data. <br><br>\n",
    "\n",
    "3. Kendall Correlation Coefficient\n",
    "\n",
    "    - The Kendall correlation coefficient is a measure of the ordinal correlation between two variables.\n",
    "    - The Kendall correlation coefficient is important because it allows us to make predictions about the future based on past data. <br><br>\n",
    "\n",
    "## Correlation vs Causation\n",
    "\n",
    "1. Correlation\n",
    "\n",
    "    - Correlation is a measure of the linear relationship between two variables.\n",
    "    - Correlation is important because it allows us to make predictions about the future based on past data. <br><br>\n",
    "\n",
    "2. Causation\n",
    "\n",
    "    - Causation is a measure of the causal relationship between two variables.\n",
    "    - Causation is important because it allows us to make predictions about the future based on past data. <br><br>\n",
    "\n",
    "## How to measure causation?\n",
    "\n",
    "1. A/B Testing\n",
    "\n",
    "    - A/B testing is a method of comparing two versions of a product or service against each other to determine which one performs better.\n",
    "    - A/B testing is important because it allows us to make predictions about the future based on past data. <br><br>\n",
    "\n",
    "2. Regression Analysis\n",
    "\n",
    "    - Regression analysis is a method of estimating the relationship between a dependent variable and one or more independent variables.\n",
    "    - Regression analysis is important because it allows us to make predictions about the future based on past data. <br><br>\n",
    "\n",
    "## Multiple Linear Regression\n",
    "\n",
    "- Multiple linear regression is a method of estimating the relationship between a dependent variable and two or more independent variables.\n",
    "- Multiple linear regression is important because it allows us to make predictions about the future based on past data. <br><br>\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "- Logistic regression is a method of estimating the relationship between a dependent variable and one or more independent variables.\n",
    "- Logistic regression is important because it allows us to make predictions about the future based on past data. <br><br>\n",
    "\n",
    "## Simpson's Paradox\n",
    "\n",
    "- Simpson's paradox is a phenomenon in probability and statistics in which a trend appears in several different groups of data but disappears or reverses when these groups are combined.\n",
    "- Simpson's paradox is important because it helps us check data looking into different groups. <br><br>\n",
    "\n",
    "## What to do when there are a lot of variables?\n",
    "\n",
    "1. Dimensionality Reduction: Dimensionality reduction is the process of reducing the number of variables in a dataset. Some examples of dimensionality reduction are:\n",
    "\n",
    "    - Principal Component Analysis (PCA)\n",
    "    - Linear Discriminant Analysis (LDA)\n",
    "    - t-distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "    - Uniform Manifold Approximation and Projection (UMAP)\n",
    "    - etc. <br><br>\n",
    "\n",
    "2. Feature Selection: Feature selection is the process of selecting the most important variables in a dataset. Some examples of feature selection are:\n",
    "\n",
    "    - Univariate Feature Selection\n",
    "    - Recursive Feature Elimination\n",
    "    - Feature Importance\n",
    "    - etc. <br><br>\n",
    "\n",
    "3. Feature Extraction: Feature extraction is the process of extracting new variables from existing variables in a dataset. Some examples of feature extraction are:\n",
    "\n",
    "    - Bag of Words\n",
    "    - Word2Vec\n",
    "    - etc. <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
